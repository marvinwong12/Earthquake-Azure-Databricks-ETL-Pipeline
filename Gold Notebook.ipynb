{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fbc0339-d3f7-4bff-a23a-cdd34b4c90ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_output = dbutils.jobs.taskValues.get(taskKey='Bronze', key = 'bronze_output')\n",
    "silver_data = dbutils.jobs.taskValues.get(taskKey='Silver',key = 'silver_output')\n",
    "\n",
    "start_date = bronze_output.get('start_date','')\n",
    "silver_adls = bronze_output.get('silver_adls','')\n",
    "gold_adls = bronze_output.get('gold_adls','')\n",
    "\n",
    "print(f\"Start Date: {start_date}, Gold ADLS: {gold_adls}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b22c9f52-8507-4397-adbf-657e2b823f0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "# Ensure the below library is installed on your cluster\n",
    "import reverse_geocoder as rg\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f0c3a4-35af-402c-b0cf-644d55f1c09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(silver_data).filter(col('time') > start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80fc0172-fcde-4986-90e0-c16f08e70fcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.limit(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1699a53e-9e47-4173-ba00-acc21a4d0f06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Retrieve the country code for a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float or str): Latitude of the location.\n",
    "    lon (float or str): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
    "\n",
    "    Example:\n",
    "    >>> get_country_details(48.8588443, 2.2943506)\n",
    "    'FR'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coordinates = (float(lat), float(lon))\n",
    "        result = rg.search(coordinates)[0].get('cc')\n",
    "        print(f\"Processed coordinates: {coordinates} -> {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing coordinates: {lat}, {lon} -> {str(e)}\")\n",
    "        return None\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ba640e9-86cc-45d2-9f79-827f8ea1e18a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# registering the udfs so they can be used on spark dataframes\n",
    "get_country_code_udf = udf(get_country_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e05aeb7-73f8-49d5-be2b-d202dbfb135c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed coordinates: (48.8588443, 2.2943506) -> FR\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'FR'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_code(48.8588443, 2.2943506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952080d1-2b46-491c-9e5e-ac02b7ad2ef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# adding country_code and city attributes\n",
    "df_with_location = \\\n",
    "                df.\\\n",
    "                    withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "605fd71e-82de-43f0-a881-a4f379fe89c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# adding significance classification\n",
    "df_with_location_sig_class = \\\n",
    "                            df_with_location.\\\n",
    "                                withColumn('sig_class', \n",
    "                                            when(col(\"sig\") < 100, \"Low\").\\\n",
    "                                            when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\").\\\n",
    "                                            otherwise(\"High\")\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b4fba3-d347-49f2-89e8-c59771148aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- longitude: double (nullable = true)\n |-- latitude: double (nullable = true)\n |-- elevation: double (nullable = true)\n |-- title: string (nullable = true)\n |-- place_description: string (nullable = true)\n |-- sig: long (nullable = true)\n |-- mag: double (nullable = true)\n |-- magType: string (nullable = true)\n |-- time: timestamp (nullable = true)\n |-- updated: timestamp (nullable = true)\n |-- country_code: string (nullable = true)\n |-- sig_class: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "df_with_location_sig_class.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d02d801-b47d-436d-9c55-a55d045c1e17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save transferred Dataframe to Gold container\n",
    "gold_output_path = f\"{gold_adls}earthquake_events_gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd106b6-20fe-4a33-a555-eb799fe57a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Append DataFrame to Silver container in Parquet format\n",
    "df_with_location_sig_class.write.mode('append').parquet(gold_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}